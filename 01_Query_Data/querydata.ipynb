{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DHIS2 Analytics API - Using Training.DHIS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Packages\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current notebook's directory\n",
    "base_dir = Path.cwd().parent  # Moves one level up from current working directory\n",
    "\n",
    "# Paths\n",
    "credentials_path = base_dir / '00_Local' / '01_Configs' / 'credentials.txt'\n",
    "data_dir = base_dir / '00_Local' / '02_Data'\n",
    "data_elements_csv = Path.cwd().parent / '00_Local' / '02_Data' / 'nd2_data_elements_ids.csv'\n",
    "org_units_levels_file = data_dir / 'organisation_units_levels.csv'\n",
    "districts_file = data_dir / 'districts.csv'\n",
    "provinces_file = data_dir / 'provinces.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load credentials from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHIS2 instance URL: https://training.eidsr.znphi.co.zm/\n"
     ]
    }
   ],
   "source": [
    "# Load credentials from the file\n",
    "credentials = {}\n",
    "with credentials_path.open('r') as file:\n",
    "    for line in file:\n",
    "        if '=' in line:\n",
    "            key, value = line.strip().split('=', 1)\n",
    "            credentials[key.strip()] = value.strip()\n",
    "\n",
    "# Extract values\n",
    "DHIS2_URL = credentials.get('DHIS2_URL')\n",
    "USERNAME = credentials.get('USERNAME')\n",
    "PASSWORD = credentials.get('PASSWORD')\n",
    "PAT = credentials.get('PAT')\n",
    "\n",
    "print(\"DHIS2 instance URL:\", DHIS2_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query DHIS2 Analytics API for available data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# My API endpoint for datasets\n",
    "endpoint = f\"{DHIS2_URL}/api/dataSets.json\"\n",
    "\n",
    "# My request with authentication\n",
    "response = requests.get(endpoint, auth=(USERNAME, PASSWORD), params={'paging': 'false'})\n",
    "\n",
    "# Stepwise check\n",
    "if response.status_code == 200:\n",
    "    datasets = response.json()\n",
    "    print(\"Data retrieved successfully!\")\n",
    "else:\n",
    "    print(\"Failed to retrieve data:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Retrieved Data in a Readable Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pretty-print the JSON response to understand the contents of the dictionary\n",
    "# print(json.dumps(datasets, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Data to a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON to DataFrame\n",
    "df = pd.DataFrame(datasets['dataSets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displayName</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cholera Vaccination</td>\n",
       "      <td>xoR1fw9UAnC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Community EBS</td>\n",
       "      <td>GWpIuhj6AEI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Community EBS Redesign</td>\n",
       "      <td>nkH6V3U9bJ8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-19 Daily Monitoring and Contact Tracing</td>\n",
       "      <td>X2vykx4vd8C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-19 Homecare Report</td>\n",
       "      <td>dBM7yaDxy9g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COVID-19 Laboratory Daily Aggregated Tool</td>\n",
       "      <td>gOr8UcpIqLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COVID-19 Surveillance Daily Aggregate Report</td>\n",
       "      <td>Ctvbrr4atAn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COVID Cases Management Daily Aggregate Report</td>\n",
       "      <td>dTFXTfmgjgv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HF-IDSR Core Function Assessment Tool</td>\n",
       "      <td>SA4ANhumZ9v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ND2 Report</td>\n",
       "      <td>BtzVmjyJ6DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ND2 Report in Sections (weekly)</td>\n",
       "      <td>L5MxHpPrfFD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Outbreak Report</td>\n",
       "      <td>QuqBVMy0hvx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Points of Entry COVID-19 Response Tool</td>\n",
       "      <td>dYonHuj6afW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Population</td>\n",
       "      <td>BZHxbZxXpkf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Revised ND2 IDSR Report</td>\n",
       "      <td>HhFnzRM31hZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      displayName           id\n",
       "0                             Cholera Vaccination  xoR1fw9UAnC\n",
       "1                                   Community EBS  GWpIuhj6AEI\n",
       "2                         Community EBS Redesign   nkH6V3U9bJ8\n",
       "3   COVID-19 Daily Monitoring and Contact Tracing  X2vykx4vd8C\n",
       "4                        COVID-19 Homecare Report  dBM7yaDxy9g\n",
       "5       COVID-19 Laboratory Daily Aggregated Tool  gOr8UcpIqLA\n",
       "6   COVID-19 Surveillance Daily Aggregate Report   Ctvbrr4atAn\n",
       "7   COVID Cases Management Daily Aggregate Report  dTFXTfmgjgv\n",
       "8          HF-IDSR Core Function Assessment Tool   SA4ANhumZ9v\n",
       "9                                      ND2 Report  BtzVmjyJ6DZ\n",
       "10                ND2 Report in Sections (weekly)  L5MxHpPrfFD\n",
       "11                                Outbreak Report  QuqBVMy0hvx\n",
       "12         Points of Entry COVID-19 Response Tool  dYonHuj6afW\n",
       "13                                    Population   BZHxbZxXpkf\n",
       "14                        Revised ND2 IDSR Report  HhFnzRM31hZ"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved to datasets.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Data for Future Analysis\n",
    "\n",
    "df.to_csv(data_dir / 'datasets.csv', index=False)\n",
    "print(\"Datasets saved to datasets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View All Organisation Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organisation Units retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# API endpoint for organisation units\n",
    "org_units_url = f\"{DHIS2_URL}/api/organisationUnits.json\"\n",
    "\n",
    "# Parameters to retrieve all units without paging\n",
    "params = {\n",
    "    'paging': 'false',  # Retrieve all records without pagination\n",
    "    'fields': 'id,displayName,level,parent[id,displayName]'  # Fetch necessary fields\n",
    "}\n",
    "\n",
    "# Request\n",
    "response = requests.get(org_units_url, auth=(USERNAME, PASSWORD), params=params)\n",
    "\n",
    "# Process the response\n",
    "if response.status_code == 200:\n",
    "    org_units = response.json()\n",
    "    print(\"Organisation Units retrieved successfully!\")\n",
    "else:\n",
    "    print(\"Error fetching organisation units:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(org_units, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the organisation unit details\n",
    "org_units_list = org_units.get('organisationUnits', [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_org_units = pd.DataFrame(org_units_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>displayName</th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'displayName': 'ea Chasefu District', 'id': '...</td>\n",
       "      <td>ae Chasefu Mini Hospital</td>\n",
       "      <td>qt4781BQa2L</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'displayName': 'ls Chilanga District', 'id': ...</td>\n",
       "      <td>Balmoral Health Post</td>\n",
       "      <td>FrOn8lcbzPb</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'displayName': 'ce Luano DIstrict', 'id': 'hP...</td>\n",
       "      <td>ce Bbusa Health Post</td>\n",
       "      <td>EPtuFlHv12i</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'displayName': 'ce Kabwe District', 'id': 'sN...</td>\n",
       "      <td>ce Blossom Surgery Clinic</td>\n",
       "      <td>S9tqzMHVdMU</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'displayName': 'ce Chisamba District', 'id': ...</td>\n",
       "      <td>ce Bombwe Health post</td>\n",
       "      <td>FIU3dK7BniN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>{'displayName': 'ls Chilanga District', 'id': ...</td>\n",
       "      <td>ZA-Apollo Rural Health Centre</td>\n",
       "      <td>sfSGuVk954T</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>{'displayName': 'ls Chilanga District', 'id': ...</td>\n",
       "      <td>Zambia Helpers Society Hospital</td>\n",
       "      <td>oqBLYbMJXcg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>{'displayName': 'ce Chibombo District', 'id': ...</td>\n",
       "      <td>zm Test Facility</td>\n",
       "      <td>BU7fjlCqw4o</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>NaN</td>\n",
       "      <td>zm Zambia Ministry of Health</td>\n",
       "      <td>PS5JpkoHHio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>{'displayName': 'mu Nakonde Urban Health Centr...</td>\n",
       "      <td>Zone 1 NHC</td>\n",
       "      <td>zf9frXaA7rQ</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 parent  \\\n",
       "0     {'displayName': 'ea Chasefu District', 'id': '...   \n",
       "1     {'displayName': 'ls Chilanga District', 'id': ...   \n",
       "2     {'displayName': 'ce Luano DIstrict', 'id': 'hP...   \n",
       "3     {'displayName': 'ce Kabwe District', 'id': 'sN...   \n",
       "4     {'displayName': 'ce Chisamba District', 'id': ...   \n",
       "...                                                 ...   \n",
       "3827  {'displayName': 'ls Chilanga District', 'id': ...   \n",
       "3828  {'displayName': 'ls Chilanga District', 'id': ...   \n",
       "3829  {'displayName': 'ce Chibombo District', 'id': ...   \n",
       "3830                                                NaN   \n",
       "3831  {'displayName': 'mu Nakonde Urban Health Centr...   \n",
       "\n",
       "                          displayName           id  level  \n",
       "0            ae Chasefu Mini Hospital  qt4781BQa2L      4  \n",
       "1                Balmoral Health Post  FrOn8lcbzPb      4  \n",
       "2                ce Bbusa Health Post  EPtuFlHv12i      4  \n",
       "3           ce Blossom Surgery Clinic  S9tqzMHVdMU      4  \n",
       "4               ce Bombwe Health post  FIU3dK7BniN      4  \n",
       "...                               ...          ...    ...  \n",
       "3827    ZA-Apollo Rural Health Centre  sfSGuVk954T      4  \n",
       "3828  Zambia Helpers Society Hospital  oqBLYbMJXcg      4  \n",
       "3829                 zm Test Facility  BU7fjlCqw4o      4  \n",
       "3830     zm Zambia Ministry of Health  PS5JpkoHHio      1  \n",
       "3831                       Zone 1 NHC  zf9frXaA7rQ      5  \n",
       "\n",
       "[3832 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organisation Unit Levels retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# API endpoint for organisation unit levels (national, provincial, district etc...)\n",
    "org_unit_levels_url = f\"{DHIS2_URL}/api/organisationUnitLevels.json\"\n",
    "\n",
    "# Parameters to retrieve all levels without paging\n",
    "params = {\n",
    "    'paging': 'false',  # Retrieve all records without pagination\n",
    "    'fields': 'id,level,displayName'  # Fetch necessary fields\n",
    "}\n",
    "\n",
    "# Request\n",
    "response = requests.get(org_unit_levels_url, auth=(USERNAME, PASSWORD), params=params)\n",
    "\n",
    "# Process the response\n",
    "if response.status_code == 200:\n",
    "    org_unit_levels = response.json()\n",
    "    print(\"Organisation Unit Levels retrieved successfully!\")\n",
    "else:\n",
    "    print(\"Error fetching organisation unit levels:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>displayName</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>National</td>\n",
       "      <td>qXnFgkCQcRC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Province</td>\n",
       "      <td>HDS8ZqmIuJh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>District</td>\n",
       "      <td>Dz7Sm3imvLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Health Facilities</td>\n",
       "      <td>MQLiogB9XBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>NHC-Zones</td>\n",
       "      <td>R2H4dpJ4PSF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level        displayName           id\n",
       "2      1           National  qXnFgkCQcRC\n",
       "4      2           Province  HDS8ZqmIuJh\n",
       "0      3           District  Dz7Sm3imvLU\n",
       "1      4  Health Facilities  MQLiogB9XBV\n",
       "3      5          NHC-Zones  R2H4dpJ4PSF"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the organisation unit levels\n",
    "org_levels_list = org_unit_levels.get('organisationUnitLevels', [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_org_levels = pd.DataFrame(org_levels_list)\n",
    "\n",
    "df_org_levels = df_org_levels.sort_values(by='level', ascending=True)\n",
    "\n",
    "df_org_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organisation_units saved to organisation_units_levels.csv\n"
     ]
    }
   ],
   "source": [
    "df_org_levels.to_csv(data_dir / 'organisation_units_levels.csv', index=False)\n",
    "print(\"Organisation_units saved to organisation_units_levels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total provinces found: 10\n",
      "Province unit IDs: AWn3s2RqgAN,utIjliUdjp8,J7PQPWAeRUk,KozcEjeTyuD,B1u1bVtIA92,dbTLdTi7s8F,SwwuteU1Ajk,q5hODNmn021,oPLMrarKeEY,g1bv2xjtV0w\n"
     ]
    }
   ],
   "source": [
    "# Filter only province-level organisation units (level 2 as shown above)\n",
    "df_provinces = df_org_units[df_org_units['level'] == 2]\n",
    "\n",
    "# Province IDs as a comma-separated string\n",
    "province_unit_ids = \",\".join(df_provinces['id'])\n",
    "\n",
    "print(\"Total provinces found:\", len(df_provinces))\n",
    "print(\"Province unit IDs:\", province_unit_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displayName</th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ce Central Province</td>\n",
       "      <td>AWn3s2RqgAN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>co Copperbelt Province</td>\n",
       "      <td>utIjliUdjp8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ea Eastern Province</td>\n",
       "      <td>J7PQPWAeRUk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>ls Lusaka Province</td>\n",
       "      <td>KozcEjeTyuD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>lu Luapula Province</td>\n",
       "      <td>B1u1bVtIA92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>mu Muchinga Province</td>\n",
       "      <td>dbTLdTi7s8F</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>no Northern Province</td>\n",
       "      <td>SwwuteU1Ajk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>nw North-Western Province</td>\n",
       "      <td>q5hODNmn021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3442</th>\n",
       "      <td>so Southern Province</td>\n",
       "      <td>oPLMrarKeEY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>we Western Province</td>\n",
       "      <td>g1bv2xjtV0w</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    displayName           id  level\n",
       "8           ce Central Province  AWn3s2RqgAN      2\n",
       "457      co Copperbelt Province  utIjliUdjp8      2\n",
       "990         ea Eastern Province  J7PQPWAeRUk      2\n",
       "1515         ls Lusaka Province  KozcEjeTyuD      2\n",
       "1837        lu Luapula Province  B1u1bVtIA92      2\n",
       "2157       mu Muchinga Province  dbTLdTi7s8F      2\n",
       "2550       no Northern Province  SwwuteU1Ajk      2\n",
       "2876  nw North-Western Province  q5hODNmn021      2\n",
       "3442       so Southern Province  oPLMrarKeEY      2\n",
       "3819        we Western Province  g1bv2xjtV0w      2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Levels in the dataset\n",
    "df_org_units['level'].unique()\n",
    "\n",
    "# Ensure the correct level is being used for provinces (assumed level 2)\n",
    "df_provinces = df_org_units[df_org_units['level'] == 2]\n",
    "\n",
    "# Check if provinces were correctly filtered\n",
    "df_provinces[['displayName', 'id', 'level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Province unit IDs: AWn3s2RqgAN;utIjliUdjp8;J7PQPWAeRUk;KozcEjeTyuD;B1u1bVtIA92;dbTLdTi7s8F;SwwuteU1Ajk;q5hODNmn021;oPLMrarKeEY;g1bv2xjtV0w\n"
     ]
    }
   ],
   "source": [
    "province_unit_ids = \";\".join([\n",
    "    \"AWn3s2RqgAN\",  # Central Province\n",
    "    \"utIjliUdjp8\",  # Copperbelt Province\n",
    "    \"J7PQPWAeRUk\",  # Eastern Province\n",
    "    \"KozcEjeTyuD\",  # Lusaka Province\n",
    "    \"B1u1bVtIA92\",  # Luapula Province\n",
    "    \"dbTLdTi7s8F\",  # Muchinga Province\n",
    "    \"SwwuteU1Ajk\",  # Northern Province\n",
    "    \"q5hODNmn021\",  # North-Western Province\n",
    "    \"oPLMrarKeEY\",  # Southern Province\n",
    "    \"g1bv2xjtV0w\"   # Western Province\n",
    "])\n",
    "\n",
    "print(\"Formatted Province unit IDs:\", province_unit_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Districts saved to districts.csv\n",
      "Provinces saved to provinces.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract and save districts (Level 3)\n",
    "df_districts = df_org_units[df_org_units['level'] == 3][['id', 'displayName', 'parent']]\n",
    "df_districts.to_csv(districts_file, index=False)\n",
    "print(f\"Districts saved to districts.csv\")\n",
    "\n",
    "# Extract and save provinces (Level 2)\n",
    "df_provinces = df_org_units[df_org_units['level'] == 2][['id', 'displayName', 'parent']]\n",
    "df_provinces.to_csv(provinces_file, index=False)\n",
    "print(f\"Provinces saved to provinces.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY ND2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ND2 Report metadata retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# ND2 Report dataset ID\n",
    "nd2_report_id = \"BtzVmjyJ6DZ\"\n",
    "\n",
    "# API endpoint\n",
    "nd2_report_url = f\"{DHIS2_URL}/api/dataSets/{nd2_report_id}.json\"\n",
    "\n",
    "# Parameters to retrieve metadata (data elements, category combos, etc.)\n",
    "params = {\n",
    "    'fields': 'id,displayName,dataSetElements[dataElement[id,displayName,valueType]],periodType',\n",
    "    'paging': 'false'\n",
    "}\n",
    "\n",
    "# Request\n",
    "response = requests.get(nd2_report_url, auth=(USERNAME, PASSWORD), params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    nd2_report_data = response.json()\n",
    "    print(\"ND2 Report metadata retrieved successfully!\")\n",
    "else:\n",
    "    print(\"Error fetching ND2 Report data:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json.dumps(nd2_report_data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data elements\n",
    "data_elements = nd2_report_data.get('dataSetElements', [])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_data_elements = pd.DataFrame([\n",
    "    {\n",
    "        'dataElement_id': element['dataElement']['id'],\n",
    "        'dataElement_name': element['dataElement']['displayName'],\n",
    "        'valueType': element['dataElement']['valueType']\n",
    "    }\n",
    "    for element in data_elements\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataElement_id</th>\n",
       "      <th>dataElement_name</th>\n",
       "      <th>valueType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J3nlyqwGFtS</td>\n",
       "      <td>Diarrhoea Non-Bloody death</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDEVv6Epwi9</td>\n",
       "      <td>Typhoid fever suspected</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tVLiX3s4oIR</td>\n",
       "      <td>Food Poisoning sent to lab</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qhTdkAWNjBG</td>\n",
       "      <td>Measles death</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SdiSDjLQdds</td>\n",
       "      <td>Maternal Death</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MFUSzvPE1vn</td>\n",
       "      <td>Trypanosomiasis sent to lab</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ZO0ULwawUDZ</td>\n",
       "      <td>SARS confirmed</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dZkt0zcIP8M</td>\n",
       "      <td>HIV death</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s6TTSztuLfH</td>\n",
       "      <td>HIV confirmed</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xH18qiCnErl</td>\n",
       "      <td>VHF (Ebola, Marburg, Lassa Fever, RVF, Crimean...</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S00RIudOpnS</td>\n",
       "      <td>Acute Viral Hepatitis sent to lab</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bsOtqcrVnzA</td>\n",
       "      <td>Diarrhoea Non-Bloody confirmed</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TqcXNARUB6f</td>\n",
       "      <td>Mumps confirmed</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ffuxfdgma0x</td>\n",
       "      <td>Shigella-(Diarrhoea With Blood</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mH1mYNOZGtT</td>\n",
       "      <td>COVID-19 suspected</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sYaNvBOadli</td>\n",
       "      <td>Mumps suspected</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vEdnZOY23PF</td>\n",
       "      <td>Rabies death</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>uwJiEGRzBOP</td>\n",
       "      <td>Chicken Pox confirmed</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dz9ycS1o4vK</td>\n",
       "      <td>Rabies confirmed</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>D2ThDRykD5G</td>\n",
       "      <td>Chicken Pox death</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataElement_id                                   dataElement_name valueType\n",
       "0     J3nlyqwGFtS                        Diarrhoea Non-Bloody death     NUMBER\n",
       "1     IDEVv6Epwi9                            Typhoid fever suspected    NUMBER\n",
       "2     tVLiX3s4oIR                         Food Poisoning sent to lab    NUMBER\n",
       "3     qhTdkAWNjBG                                     Measles death     NUMBER\n",
       "4     SdiSDjLQdds                                     Maternal Death    NUMBER\n",
       "5     MFUSzvPE1vn                        Trypanosomiasis sent to lab    NUMBER\n",
       "6     ZO0ULwawUDZ                                    SARS confirmed     NUMBER\n",
       "7     dZkt0zcIP8M                                         HIV death     NUMBER\n",
       "8     s6TTSztuLfH                                     HIV confirmed     NUMBER\n",
       "9     xH18qiCnErl  VHF (Ebola, Marburg, Lassa Fever, RVF, Crimean...    NUMBER\n",
       "10    S00RIudOpnS                  Acute Viral Hepatitis sent to lab    NUMBER\n",
       "11    bsOtqcrVnzA                    Diarrhoea Non-Bloody confirmed     NUMBER\n",
       "12    TqcXNARUB6f                                    Mumps confirmed    NUMBER\n",
       "13    ffuxfdgma0x                    Shigella-(Diarrhoea With Blood     NUMBER\n",
       "14    mH1mYNOZGtT                                COVID-19 suspected     NUMBER\n",
       "15    sYaNvBOadli                                    Mumps suspected    NUMBER\n",
       "16    vEdnZOY23PF                                      Rabies death     NUMBER\n",
       "17    uwJiEGRzBOP                             Chicken Pox confirmed     NUMBER\n",
       "18    dz9ycS1o4vK                                  Rabies confirmed     NUMBER\n",
       "19    D2ThDRykD5G                                  Chicken Pox death    NUMBER"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_elements.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ND2 Data Elements saved to df_data_elements.csv\n"
     ]
    }
   ],
   "source": [
    "df_data_elements.to_csv(data_dir / 'data_elements.csv', index=False)\n",
    "print(\"ND2 Data Elements saved to df_data_elements.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ND2 Cholera Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cholera Data Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataElement_id</th>\n",
       "      <th>dataElement_name</th>\n",
       "      <th>valueType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AzkTqGTlreJ</td>\n",
       "      <td>Cholera confirmed</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>gMy3ugmaS8z</td>\n",
       "      <td>Cholera sent to lab</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>norzLTZKFeO</td>\n",
       "      <td>Cholera suspected</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Ay3ZqJMukSP</td>\n",
       "      <td>Cholera death</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataElement_id     dataElement_name valueType\n",
       "47     AzkTqGTlreJ   Cholera confirmed     NUMBER\n",
       "84     gMy3ugmaS8z  Cholera sent to lab    NUMBER\n",
       "99     norzLTZKFeO    Cholera suspected    NUMBER\n",
       "102    Ay3ZqJMukSP        Cholera death    NUMBER"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where 'dataElement_name' contains 'Cholera'\n",
    "cholera_data_elements = df_data_elements[df_data_elements['dataElement_name'].str.contains('Cholera', case=False, na=False)]\n",
    "\n",
    "# Display filtered elements\n",
    "cholera_data_elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholera data elements saved to cholera_data_elements.csv\n"
     ]
    }
   ],
   "source": [
    "cholera_data_elements.to_csv(data_dir / 'cholera_data_elements.csv', index=False)\n",
    "print(\"Cholera data elements saved to cholera_data_elements.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholera Data Element IDs: AzkTqGTlreJ;gMy3ugmaS8z;norzLTZKFeO;Ay3ZqJMukSP\n"
     ]
    }
   ],
   "source": [
    "cholera_element_ids = \";\".join(cholera_data_elements['dataElement_id'])\n",
    "\n",
    "print(\"Cholera Data Element IDs:\", cholera_element_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Cholera Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholera data retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# DHIS2 API URL for analytics data\n",
    "analytics_url = f\"{DHIS2_URL}/api/analytics.json\"\n",
    "\n",
    "# Cholera element IDs from the dataset\n",
    "cholera_element_ids = \"Ay3ZqJMukSP;norzLTZKFeO;gMy3ugmaS8z;AzkTqGTlreJ\"\n",
    "\n",
    "# Define the period of interest (January 2024 to December 2024)\n",
    "period_range = \";\".join([pd.to_datetime(date).strftime('%Y%m') for date in pd.date_range(start=\"2024-01-01\", end=\"2024-12-31\", freq='MS')])\n",
    "\n",
    "# Define national-level organisation unit (Ministry of Health)\n",
    "national_org_unit_id = \"PS5JpkoHHio\"\n",
    "\n",
    "# Construct API query parameters\n",
    "params = {\n",
    "    'dimension': [\n",
    "        f'dx:{cholera_element_ids}',  # Cholera data element IDs\n",
    "        f'pe:{period_range}',  # Monthly periods for 2024\n",
    "        f'ou:{national_org_unit_id}'  # National org unit\n",
    "    ],\n",
    "    'displayProperty': 'NAME'\n",
    "}\n",
    "\n",
    "# Request data from DHIS2 API\n",
    "response = requests.get(analytics_url, auth=(USERNAME, PASSWORD), params=params)\n",
    "\n",
    "# Check response status\n",
    "if response.status_code == 200:\n",
    "    cholera_data = response.json()\n",
    "    print(\"Cholera data retrieved successfully!\")\n",
    "else:\n",
    "    raise Exception(f\"Error retrieving Cholera data: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert API response to DataFrame\n",
    "if 'rows' in cholera_data:\n",
    "    df_cholera = pd.DataFrame(cholera_data['rows'], columns=['dataElement', 'period', 'orgUnit', 'value'])\n",
    "\n",
    "    # Convert period to readable format (YYYYMM to Month-Year)\n",
    "    df_cholera['Date'] = pd.to_datetime(df_cholera['period'], format='%Y%m').dt.strftime('%b-%Y')\n",
    "\n",
    "    # Map element IDs to their respective names\n",
    "    cholera_mapping = {\n",
    "        \"Ay3ZqJMukSP\": \"Cholera death\",\n",
    "        \"norzLTZKFeO\": \"Cholera suspected\",\n",
    "        \"gMy3ugmaS8z\": \"Cholera sent to lab\",\n",
    "        \"AzkTqGTlreJ\": \"Cholera confirmed\"\n",
    "    }\n",
    "\n",
    "    df_cholera['dataElement'] = df_cholera['dataElement'].map(cholera_mapping)\n",
    "\n",
    "    # Convert 'value' column to numeric and ensure integer values\n",
    "    df_cholera['value'] = pd.to_numeric(df_cholera['value'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Pivot table to restructure the data\n",
    "    df_cholera_pivot = df_cholera.pivot_table(index='Date', columns='dataElement', values='value', aggfunc='sum').reset_index()\n",
    "\n",
    "    # Ensure correct column ordering and fill missing columns with 0\n",
    "    required_columns = ['Date', 'Cholera suspected', 'Cholera sent to lab', 'Cholera death', 'Cholera confirmed']\n",
    "\n",
    "    for col in required_columns:\n",
    "        if col not in df_cholera_pivot.columns:\n",
    "            df_cholera_pivot[col] = 0  # Fill missing columns with 0\n",
    "\n",
    "    df_cholera_pivot = df_cholera_pivot[required_columns]\n",
    "\n",
    "    # Convert Date column for sorting\n",
    "    df_cholera_pivot['Date'] = pd.to_datetime(df_cholera_pivot['Date'], format='%b-%Y')\n",
    "\n",
    "    # Sort by date and convert it back to string\n",
    "    df_cholera_pivot = df_cholera_pivot.sort_values(by='Date').reset_index(drop=True)\n",
    "    df_cholera_pivot['Date'] = df_cholera_pivot['Date'].dt.strftime('%b-%Y')\n",
    "\n",
    "    # Convert all numerical columns to integers to remove decimals\n",
    "    for col in df_cholera_pivot.columns:\n",
    "        if col != 'Date':  # Exclude Date column from conversion\n",
    "            df_cholera_pivot[col] = df_cholera_pivot[col].fillna(0).astype(int)\n",
    "\n",
    "else:\n",
    "    print(\"No Cholera data found for the selected period.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataElement</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cholera suspected</th>\n",
       "      <th>Cholera sent to lab</th>\n",
       "      <th>Cholera death</th>\n",
       "      <th>Cholera confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan-2024</td>\n",
       "      <td>9117</td>\n",
       "      <td>1844</td>\n",
       "      <td>132</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb-2024</td>\n",
       "      <td>4791</td>\n",
       "      <td>1697</td>\n",
       "      <td>31</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar-2024</td>\n",
       "      <td>1542</td>\n",
       "      <td>398</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr-2024</td>\n",
       "      <td>751</td>\n",
       "      <td>213</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May-2024</td>\n",
       "      <td>197</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun-2024</td>\n",
       "      <td>133</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jul-2024</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aug-2024</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sep-2024</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oct-2024</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nov-2024</td>\n",
       "      <td>52</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dec-2024</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataElement      Date  Cholera suspected  Cholera sent to lab  Cholera death  \\\n",
       "0            Jan-2024               9117                 1844            132   \n",
       "1            Feb-2024               4791                 1697             31   \n",
       "2            Mar-2024               1542                  398              7   \n",
       "3            Apr-2024                751                  213             12   \n",
       "4            May-2024                197                  142              1   \n",
       "5            Jun-2024                133                   70              0   \n",
       "6            Jul-2024                 27                   24              0   \n",
       "7            Aug-2024                 45                    5              0   \n",
       "8            Sep-2024                141                    1              0   \n",
       "9            Oct-2024                 49                    9              0   \n",
       "10           Nov-2024                 52                   25              1   \n",
       "11           Dec-2024                 58                   19              0   \n",
       "\n",
       "dataElement  Cholera confirmed  \n",
       "0                          719  \n",
       "1                         1038  \n",
       "2                          114  \n",
       "3                           38  \n",
       "4                           55  \n",
       "5                           99  \n",
       "6                            6  \n",
       "7                            0  \n",
       "8                            0  \n",
       "9                            0  \n",
       "10                           0  \n",
       "11                          11  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cholera_pivot.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facility-Level Weekly Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of Concept: January Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing and saving facility-level data with organisation details...\n",
      "INFO:__main__:Fetching facility-level data from DHIS2...\n",
      "INFO:__main__:Organisation units loaded and cleaned successfully.\n",
      "INFO:__main__:Facilities data fetched successfully.\n",
      "INFO:__main__:Facility-level data fetched successfully.\n",
      "INFO:__main__:Facility-level data with organisation details saved.\n"
     ]
    }
   ],
   "source": [
    "# Read data elements from dataframe\n",
    "dx_ids = ';'.join(df_data_elements['dataElement_id'].tolist())\n",
    "\n",
    "# Use facility level ID\n",
    "facility_level_id = \"MQLiogB9XBV\"\n",
    "\n",
    "# Parse parent column to extract IDs from string representation\n",
    "def parse_parent_column(df):\n",
    "    \"\"\" Extract parent ID from string dictionary in the 'parent' column. \"\"\"\n",
    "    df['parent'] = df['parent'].apply(lambda x: ast.literal_eval(x)['id'] if pd.notnull(x) else None)\n",
    "    return df\n",
    "\n",
    "# Fetch facility-level organisation units from DHIS2\n",
    "def fetch_facilities():\n",
    "    \"\"\"Fetch all facilities (level 4) from DHIS2 and store them in a dataframe.\"\"\"\n",
    "    url = f\"{DHIS2_URL}/api/organisationUnits.json\"\n",
    "    params = {\"filter\": \"level:eq:4\", \"paging\": \"false\", \"fields\": \"id,displayName,parent[id]\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, auth=HTTPBasicAuth(USERNAME, PASSWORD))\n",
    "        response.raise_for_status()\n",
    "        facilities_data = response.json()\n",
    "        facilities_df = pd.DataFrame(facilities_data['organisationUnits'])\n",
    "\n",
    "        # Parse the parent ID from dictionary and rename displayName to facility_name\n",
    "        facilities_df['parent'] = facilities_df['parent'].apply(lambda x: x['id'] if pd.notnull(x) else None)\n",
    "        facilities_df.rename(columns={'displayName': 'facility_name'}, inplace=True)\n",
    "\n",
    "        logger.info(\"Facilities data fetched successfully.\")\n",
    "        return facilities_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching facility data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load organisation unit data for districts and provinces\n",
    "def load_organisation_units():\n",
    "    \"\"\" Load and clean organisation units. \"\"\"\n",
    "    try:\n",
    "        districts = pd.read_csv(districts_file)\n",
    "        provinces = pd.read_csv(provinces_file)\n",
    "\n",
    "        # Extract parent IDs from string dictionary format\n",
    "        districts = parse_parent_column(districts)\n",
    "        provinces = parse_parent_column(provinces)\n",
    "\n",
    "        logger.info(\"Organisation units loaded and cleaned successfully.\")\n",
    "        return districts, provinces\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"Organisation units file not found: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading organisation units: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Convert week string to date\n",
    "def week_to_date(week_str):\n",
    "    year, week = int(week_str[:4]), int(week_str[5:])\n",
    "    first_day_of_year = datetime(year, 1, 1)\n",
    "    first_week_start = first_day_of_year - timedelta(days=first_day_of_year.weekday())\n",
    "    return first_week_start + timedelta(weeks=week - 1)\n",
    "\n",
    "# Fetch and process DHIS2 analytics data\n",
    "def fetch_and_transform_data():\n",
    "    logger.info(\"Fetching facility-level data from DHIS2...\")\n",
    "    \n",
    "    districts, provinces = load_organisation_units()\n",
    "    facilities_df = fetch_facilities()\n",
    "    \n",
    "    if districts is None or provinces is None or facilities_df is None:\n",
    "        return None\n",
    "\n",
    "    url = f'{DHIS2_URL}/api/analytics.json'\n",
    "    params = {\n",
    "        \"dimension\": f\"dx:{dx_ids},pe:2024W01;2024W02;2024W03;2024W04,ou:LEVEL-{facility_level_id}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, auth=HTTPBasicAuth(USERNAME, PASSWORD))\n",
    "        response.raise_for_status()\n",
    "        logger.info(\"Facility-level data fetched successfully.\")\n",
    "        data = response.json()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        logger.error(f\"HTTP error: {err}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        logger.error(f\"Request error: {err}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        headers = data.get('headers', [])\n",
    "        rows = data.get('rows', [])\n",
    "        columns = [header['name'] for header in headers]\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "        df['date'] = df['pe'].apply(week_to_date)\n",
    "        df.sort_values('date', ascending=False, inplace=True)\n",
    "\n",
    "        df['value'] = pd.to_numeric(df['value'], downcast='integer', errors='coerce')\n",
    "        df = df.merge(df_data_elements, left_on='dx', right_on='dataElement_id', how='left')\n",
    "        df['dx'] = df['dataElement_name']\n",
    "        df.drop(['dataElement_name', 'dataElement_id'], axis=1, inplace=True)\n",
    "\n",
    "        # Merge facility with districts and include facility name\n",
    "        df = df.merge(facilities_df[['id', 'facility_name', 'parent']], left_on='ou', right_on='id', how='left')\n",
    "        df.rename(columns={'id': 'facility_id', 'parent': 'district_id'}, inplace=True)\n",
    "\n",
    "        df = df.merge(districts[['id', 'displayName', 'parent']], left_on='district_id', right_on='id', how='left')\n",
    "        df.rename(columns={'displayName': 'district_name', 'parent': 'province_id'}, inplace=True)\n",
    "\n",
    "        # Merge districts with provinces\n",
    "        df = df.merge(provinces[['id', 'displayName']], left_on='province_id', right_on='id', how='left')\n",
    "        df.rename(columns={'displayName': 'province_name'}, inplace=True)\n",
    "\n",
    "        # Pivot data including the new columns\n",
    "        pivoted_df = df.pivot_table(index=['pe', 'facility_id', 'district_id', 'province_id', 'facility_name', 'district_name', 'province_name', 'date'], \n",
    "                                columns='dx', \n",
    "                                values='value', \n",
    "                                aggfunc='first')\n",
    "        \n",
    "        pivoted_df.reset_index(inplace=True)\n",
    "        pivoted_df.fillna(0, inplace=True)\n",
    "        pivoted_df.rename(columns={'pe': 'period'}, inplace=True)\n",
    "\n",
    "        # Convert columns to integer where applicable\n",
    "        excluded_columns = ['dx', 'period', 'facility_id', 'district_id', 'province_id', 'facility_name', 'district_name', 'province_name', 'date']\n",
    "        columns_to_convert = [col for col in pivoted_df.columns if col not in excluded_columns]\n",
    "        for column in columns_to_convert:\n",
    "            pivoted_df[column] = pd.to_numeric(pivoted_df[column], downcast='integer', errors='coerce')\n",
    "\n",
    "        return pivoted_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Process the data and save to CSV\n",
    "def process_data():\n",
    "    logger.info(\"Processing and saving facility-level data with organisation details...\")\n",
    "\n",
    "    df = fetch_and_transform_data()\n",
    "    if df is None:\n",
    "        logger.error(\"Data processing failed. Skipping saving steps.\")\n",
    "        return\n",
    "\n",
    "    output_file = data_dir / 'facility_january_2024_with_org_details.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    logger.info(\"Facility-level data with organisation details saved.\")\n",
    "\n",
    "# Execute processing function\n",
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_data_january = pd.read_csv(data_dir / 'facility_january_2024_with_org_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>facility_id</th>\n",
       "      <th>district_id</th>\n",
       "      <th>province_id</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>district_name</th>\n",
       "      <th>province_name</th>\n",
       "      <th>date</th>\n",
       "      <th>AEFI sent to lab</th>\n",
       "      <th>AEFI suspected</th>\n",
       "      <th>...</th>\n",
       "      <th>Trypanosomiasis confirmed</th>\n",
       "      <th>Trypanosomiasis sent to lab</th>\n",
       "      <th>Trypanosomiasis suspected</th>\n",
       "      <th>Tuberculosis confirmed</th>\n",
       "      <th>Tuberculosis death</th>\n",
       "      <th>Tuberculosis sent to lab</th>\n",
       "      <th>Tuberculosis suspected</th>\n",
       "      <th>Typhoid fever confirmed</th>\n",
       "      <th>Typhoid fever sent to Lab</th>\n",
       "      <th>Typhoid fever suspected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>A2SSdvZe7ur</td>\n",
       "      <td>svOkUE0zEKJ</td>\n",
       "      <td>q5hODNmn021</td>\n",
       "      <td>nw Lumwe Health Post</td>\n",
       "      <td>nw Mufumbwe District</td>\n",
       "      <td>nw North-Western Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>A2mkoh0Qoh1</td>\n",
       "      <td>PlQiD2woAPw</td>\n",
       "      <td>SwwuteU1Ajk</td>\n",
       "      <td>no Pecha Health Post</td>\n",
       "      <td>no Lunte District</td>\n",
       "      <td>no Northern Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>A4vc3yQR2An</td>\n",
       "      <td>SJjjM0qNelL</td>\n",
       "      <td>SwwuteU1Ajk</td>\n",
       "      <td>no Chikwanda Health Post</td>\n",
       "      <td>no Senga District</td>\n",
       "      <td>no Northern Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>A6Zdi9v8spx</td>\n",
       "      <td>WUGwOojuXhn</td>\n",
       "      <td>dbTLdTi7s8F</td>\n",
       "      <td>mu Mukungule Rural Health Centre</td>\n",
       "      <td>mu Mpika District</td>\n",
       "      <td>mu Muchinga Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>A6hsoKzGQh5</td>\n",
       "      <td>SQT8xjbvWwf</td>\n",
       "      <td>oPLMrarKeEY</td>\n",
       "      <td>so Muunga Rural Health Centre</td>\n",
       "      <td>so Itezhi-tezhi District</td>\n",
       "      <td>so Southern Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>A6kk1S24wfa</td>\n",
       "      <td>DM5Sjew7MCn</td>\n",
       "      <td>oPLMrarKeEY</td>\n",
       "      <td>so Prison Urban Health Centre</td>\n",
       "      <td>so Livingstone District</td>\n",
       "      <td>so Southern Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>A8TmYeix1cv</td>\n",
       "      <td>H8e2u6ULtJn</td>\n",
       "      <td>g1bv2xjtV0w</td>\n",
       "      <td>we Mata Rural Health Centre</td>\n",
       "      <td>we Senanga District</td>\n",
       "      <td>we Western Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>A9BC0fz8cxX</td>\n",
       "      <td>SfFrfySzRgY</td>\n",
       "      <td>utIjliUdjp8</td>\n",
       "      <td>co Muchindushi Health Post</td>\n",
       "      <td>co Mpongwe District</td>\n",
       "      <td>co Copperbelt Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>ABOFImxcg03</td>\n",
       "      <td>oEBf29y8JP8</td>\n",
       "      <td>AWn3s2RqgAN</td>\n",
       "      <td>ce Shimukuni Rural Health Centre</td>\n",
       "      <td>ce Chibombo District</td>\n",
       "      <td>ce Central Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024W1</td>\n",
       "      <td>ABcUyezNjiu</td>\n",
       "      <td>A84b9TjHfN4</td>\n",
       "      <td>B1u1bVtIA92</td>\n",
       "      <td>lu Mwansakombe Rural Health Centre</td>\n",
       "      <td>lu Chifunabuli District</td>\n",
       "      <td>lu Luapula Province</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   period  facility_id  district_id  province_id  \\\n",
       "0  2024W1  A2SSdvZe7ur  svOkUE0zEKJ  q5hODNmn021   \n",
       "1  2024W1  A2mkoh0Qoh1  PlQiD2woAPw  SwwuteU1Ajk   \n",
       "2  2024W1  A4vc3yQR2An  SJjjM0qNelL  SwwuteU1Ajk   \n",
       "3  2024W1  A6Zdi9v8spx  WUGwOojuXhn  dbTLdTi7s8F   \n",
       "4  2024W1  A6hsoKzGQh5  SQT8xjbvWwf  oPLMrarKeEY   \n",
       "5  2024W1  A6kk1S24wfa  DM5Sjew7MCn  oPLMrarKeEY   \n",
       "6  2024W1  A8TmYeix1cv  H8e2u6ULtJn  g1bv2xjtV0w   \n",
       "7  2024W1  A9BC0fz8cxX  SfFrfySzRgY  utIjliUdjp8   \n",
       "8  2024W1  ABOFImxcg03  oEBf29y8JP8  AWn3s2RqgAN   \n",
       "9  2024W1  ABcUyezNjiu  A84b9TjHfN4  B1u1bVtIA92   \n",
       "\n",
       "                        facility_name             district_name  \\\n",
       "0                nw Lumwe Health Post      nw Mufumbwe District   \n",
       "1                no Pecha Health Post         no Lunte District   \n",
       "2            no Chikwanda Health Post         no Senga District   \n",
       "3    mu Mukungule Rural Health Centre         mu Mpika District   \n",
       "4       so Muunga Rural Health Centre  so Itezhi-tezhi District   \n",
       "5       so Prison Urban Health Centre   so Livingstone District   \n",
       "6         we Mata Rural Health Centre       we Senanga District   \n",
       "7          co Muchindushi Health Post       co Mpongwe District   \n",
       "8    ce Shimukuni Rural Health Centre      ce Chibombo District   \n",
       "9  lu Mwansakombe Rural Health Centre   lu Chifunabuli District   \n",
       "\n",
       "               province_name        date  AEFI sent to lab  AEFI suspected  \\\n",
       "0  nw North-Western Province  2024-01-01                 0               0   \n",
       "1       no Northern Province  2024-01-01                 0               0   \n",
       "2       no Northern Province  2024-01-01                 0               0   \n",
       "3       mu Muchinga Province  2024-01-01                 0               0   \n",
       "4       so Southern Province  2024-01-01                 0               0   \n",
       "5       so Southern Province  2024-01-01                 0               0   \n",
       "6        we Western Province  2024-01-01                 0               0   \n",
       "7     co Copperbelt Province  2024-01-01                 0               0   \n",
       "8        ce Central Province  2024-01-01                 0               0   \n",
       "9        lu Luapula Province  2024-01-01                 0               0   \n",
       "\n",
       "   ...  Trypanosomiasis confirmed   Trypanosomiasis sent to lab  \\\n",
       "0  ...                           0                            0   \n",
       "1  ...                           0                            0   \n",
       "2  ...                           0                            0   \n",
       "3  ...                           0                            0   \n",
       "4  ...                           0                            0   \n",
       "5  ...                           0                            0   \n",
       "6  ...                           0                            0   \n",
       "7  ...                           0                            0   \n",
       "8  ...                           0                            0   \n",
       "9  ...                           0                            0   \n",
       "\n",
       "   Trypanosomiasis suspected  Tuberculosis confirmed   Tuberculosis death   \\\n",
       "0                          0                        0                    0   \n",
       "1                          0                        0                    0   \n",
       "2                          0                        0                    0   \n",
       "3                          0                        0                    0   \n",
       "4                          0                        0                    0   \n",
       "5                          0                        0                    0   \n",
       "6                          0                        0                    0   \n",
       "7                          0                        0                    0   \n",
       "8                          0                        0                    0   \n",
       "9                          0                        0                    0   \n",
       "\n",
       "   Tuberculosis sent to lab   Tuberculosis suspected  \\\n",
       "0                          0                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "3                          0                      24   \n",
       "4                          0                       0   \n",
       "5                         29                      29   \n",
       "6                          1                       1   \n",
       "7                          0                       0   \n",
       "8                          0                       0   \n",
       "9                          0                       0   \n",
       "\n",
       "   Typhoid fever confirmed   Typhoid fever sent to Lab   \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "5                         0                           0   \n",
       "6                         0                           0   \n",
       "7                         0                           0   \n",
       "8                         0                           0   \n",
       "9                         0                           0   \n",
       "\n",
       "   Typhoid fever suspected  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "5                        0  \n",
       "6                        0  \n",
       "7                        0  \n",
       "8                        0  \n",
       "9                        0  \n",
       "\n",
       "[10 rows x 88 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facility_data_january.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "current_week = int(datetime.today().strftime(\"%V\"))\n",
    "print(current_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing and saving facility-level data with organisation details...\n",
      "INFO:__main__:Fetching facility-level data from DHIS2...\n",
      "INFO:__main__:Organisation units loaded and cleaned successfully.\n",
      "INFO:__main__:Facilities data fetched successfully.\n",
      "INFO:__main__:Facility-level data fetched successfully.\n",
      "INFO:__main__:Facility-level data with organisation details saved.\n"
     ]
    }
   ],
   "source": [
    "# Read data elements from dataframe\n",
    "dx_ids = ';'.join(df_data_elements['dataElement_id'].tolist())\n",
    "\n",
    "# Use facility level ID\n",
    "facility_level_id = \"MQLiogB9XBV\"\n",
    "\n",
    "# Parse parent column to extract IDs from string representation\n",
    "def parse_parent_column(df):\n",
    "    \"\"\" Extract parent ID from string dictionary in the 'parent' column. \"\"\"\n",
    "    df['parent'] = df['parent'].apply(lambda x: ast.literal_eval(x)['id'] if pd.notnull(x) else None)\n",
    "    return df\n",
    "\n",
    "# Fetch facility-level organisation units from DHIS2\n",
    "def fetch_facilities():\n",
    "    \"\"\"Fetch all facilities (level 4) from DHIS2 and store them in a dataframe.\"\"\"\n",
    "    url = f\"{DHIS2_URL}/api/organisationUnits.json\"\n",
    "    params = {\"filter\": \"level:eq:4\", \"paging\": \"false\", \"fields\": \"id,displayName,parent[id]\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, auth=HTTPBasicAuth(USERNAME, PASSWORD))\n",
    "        response.raise_for_status()\n",
    "        facilities_data = response.json()\n",
    "        facilities_df = pd.DataFrame(facilities_data['organisationUnits'])\n",
    "\n",
    "        # Parse the parent ID from dictionary and rename displayName to facility_name\n",
    "        facilities_df['parent'] = facilities_df['parent'].apply(lambda x: x['id'] if pd.notnull(x) else None)\n",
    "        facilities_df.rename(columns={'displayName': 'facility_name'}, inplace=True)\n",
    "\n",
    "        logger.info(\"Facilities data fetched successfully.\")\n",
    "        return facilities_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error fetching facility data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load organisation unit data for districts and provinces\n",
    "def load_organisation_units():\n",
    "    \"\"\" Load and clean organisation units. \"\"\"\n",
    "    try:\n",
    "        districts = pd.read_csv(districts_file)\n",
    "        provinces = pd.read_csv(provinces_file)\n",
    "\n",
    "        # Extract parent IDs from string dictionary format\n",
    "        districts = parse_parent_column(districts)\n",
    "        provinces = parse_parent_column(provinces)\n",
    "\n",
    "        logger.info(\"Organisation units loaded and cleaned successfully.\")\n",
    "        return districts, provinces\n",
    "    except FileNotFoundError as e:\n",
    "        logger.error(f\"Organisation units file not found: {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading organisation units: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Convert week string to date\n",
    "def week_to_date(week_str):\n",
    "    year, week = int(week_str[:4]), int(week_str[5:])\n",
    "    first_day_of_year = datetime(year, 1, 1)\n",
    "    first_week_start = first_day_of_year - timedelta(days=first_day_of_year.weekday())\n",
    "    return first_week_start + timedelta(weeks=week - 1)\n",
    "\n",
    "# Fetch and process DHIS2 analytics data\n",
    "def fetch_and_transform_data():\n",
    "    logger.info(\"Fetching facility-level data from DHIS2...\")\n",
    "    \n",
    "    districts, provinces = load_organisation_units()\n",
    "    facilities_df = fetch_facilities()\n",
    "    \n",
    "    if districts is None or provinces is None or facilities_df is None:\n",
    "        return None\n",
    "\n",
    "    url = f'{DHIS2_URL}/api/analytics.json'\n",
    "    params = {\n",
    "        \"dimension\": f\"dx:{dx_ids},pe:LAST_12_MONTHS,ou:LEVEL-{facility_level_id}\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, auth=HTTPBasicAuth(USERNAME, PASSWORD))\n",
    "        response.raise_for_status()\n",
    "        logger.info(\"Facility-level data fetched successfully.\")\n",
    "        data = response.json()\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        logger.error(f\"HTTP error: {err}\")\n",
    "        return None\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        logger.error(f\"Request error: {err}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        headers = data.get('headers', [])\n",
    "        rows = data.get('rows', [])\n",
    "        columns = [header['name'] for header in headers]\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "        df['date'] = df['pe'].apply(week_to_date)\n",
    "        df.sort_values('date', ascending=False, inplace=True)\n",
    "\n",
    "        df['value'] = pd.to_numeric(df['value'], downcast='integer', errors='coerce')\n",
    "        df = df.merge(df_data_elements, left_on='dx', right_on='dataElement_id', how='left')\n",
    "        df['dx'] = df['dataElement_name']\n",
    "        df.drop(['dataElement_name', 'dataElement_id'], axis=1, inplace=True)\n",
    "\n",
    "        # Merge facility with districts and include facility name\n",
    "        df = df.merge(facilities_df[['id', 'facility_name', 'parent']], left_on='ou', right_on='id', how='left')\n",
    "        df.rename(columns={'id': 'facility_id', 'parent': 'district_id'}, inplace=True)\n",
    "\n",
    "        df = df.merge(districts[['id', 'displayName', 'parent']], left_on='district_id', right_on='id', how='left')\n",
    "        df.rename(columns={'displayName': 'district_name', 'parent': 'province_id'}, inplace=True)\n",
    "\n",
    "        # Merge districts with provinces\n",
    "        df = df.merge(provinces[['id', 'displayName']], left_on='province_id', right_on='id', how='left')\n",
    "        df.rename(columns={'displayName': 'province_name'}, inplace=True)\n",
    "\n",
    "        # Pivot data including the new columns\n",
    "        pivoted_df = df.pivot_table(index=['pe', 'facility_id', 'district_id', 'province_id', 'facility_name', 'district_name', 'province_name', 'date'], \n",
    "                                columns='dx', \n",
    "                                values='value', \n",
    "                                aggfunc='first')\n",
    "        \n",
    "        pivoted_df.reset_index(inplace=True)\n",
    "        pivoted_df.fillna(0, inplace=True)\n",
    "        pivoted_df.rename(columns={'pe': 'period'}, inplace=True)\n",
    "\n",
    "        # Convert columns to integer where applicable\n",
    "        excluded_columns = ['dx', 'period', 'facility_id', 'district_id', 'province_id', 'facility_name', 'district_name', 'province_name', 'date']\n",
    "        columns_to_convert = [col for col in pivoted_df.columns if col not in excluded_columns]\n",
    "        for column in columns_to_convert:\n",
    "            pivoted_df[column] = pd.to_numeric(pivoted_df[column], downcast='integer', errors='coerce')\n",
    "\n",
    "        return pivoted_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Process the data and save to CSV\n",
    "def process_data():\n",
    "    logger.info(\"Processing and saving facility-level data with organisation details...\")\n",
    "\n",
    "    df = fetch_and_transform_data()\n",
    "    if df is None:\n",
    "        logger.error(\"Data processing failed. Skipping saving steps.\")\n",
    "        return\n",
    "\n",
    "    output_file = data_dir / 'facility_12_months.csv'\n",
    "    df.to_csv(output_file, index=False)\n",
    "    logger.info(\"Facility-level data with organisation details saved.\")\n",
    "\n",
    "# Execute processing function\n",
    "process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "facility_12_months = pd.read_csv(data_dir / \"facility_12_months.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>facility_id</th>\n",
       "      <th>district_id</th>\n",
       "      <th>province_id</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>district_name</th>\n",
       "      <th>province_name</th>\n",
       "      <th>date</th>\n",
       "      <th>AEFI confirmed</th>\n",
       "      <th>AEFI death</th>\n",
       "      <th>...</th>\n",
       "      <th>Typhoid fever confirmed</th>\n",
       "      <th>Typhoid fever death</th>\n",
       "      <th>Typhoid fever sent to Lab</th>\n",
       "      <th>Typhoid fever suspected</th>\n",
       "      <th>VHF (Ebola, Marburg, Lassa Fever, RVF, Crimean-Congo) death</th>\n",
       "      <th>VHF (Ebola, Marburg, Lassa Fever, RVF, Crimean-Congo) sent to lab</th>\n",
       "      <th>VHF (Ebola, Marburg, Lassa Fever, RVF, Crimean-Congo) suspected</th>\n",
       "      <th>Yellow fever death</th>\n",
       "      <th>Yellow fever sent to lab</th>\n",
       "      <th>Yellow fever suspected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35930</th>\n",
       "      <td>202412</td>\n",
       "      <td>zv11JO8uQyB</td>\n",
       "      <td>xu3OhvvaqO2</td>\n",
       "      <td>g1bv2xjtV0w</td>\n",
       "      <td>we Lewanika Referral Hospital</td>\n",
       "      <td>we Mongu District</td>\n",
       "      <td>we Western Province</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35931</th>\n",
       "      <td>202412</td>\n",
       "      <td>zvNTAGjh6dg</td>\n",
       "      <td>H8e2u6ULtJn</td>\n",
       "      <td>g1bv2xjtV0w</td>\n",
       "      <td>we Mutwa Health Post</td>\n",
       "      <td>we Senanga District</td>\n",
       "      <td>we Western Province</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35932</th>\n",
       "      <td>202412</td>\n",
       "      <td>zvdAaDU7yC6</td>\n",
       "      <td>EdEpJ41rhF6</td>\n",
       "      <td>SwwuteU1Ajk</td>\n",
       "      <td>no Masamba Rural Health Centre</td>\n",
       "      <td>no Mbala District</td>\n",
       "      <td>no Northern Province</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35933</th>\n",
       "      <td>202412</td>\n",
       "      <td>zvjggVwOhQP</td>\n",
       "      <td>ydyJb1RAy4U</td>\n",
       "      <td>J7PQPWAeRUk</td>\n",
       "      <td>ea Chimphamba Health Post</td>\n",
       "      <td>ea Chama District</td>\n",
       "      <td>ea Eastern Province</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35934</th>\n",
       "      <td>202412</td>\n",
       "      <td>zzJ3hvbee0l</td>\n",
       "      <td>RXl1ctHnd1A</td>\n",
       "      <td>B1u1bVtIA92</td>\n",
       "      <td>lu Shoti Health Post</td>\n",
       "      <td>lu Mansa District</td>\n",
       "      <td>lu Luapula Province</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       period  facility_id  district_id  province_id  \\\n",
       "35930  202412  zv11JO8uQyB  xu3OhvvaqO2  g1bv2xjtV0w   \n",
       "35931  202412  zvNTAGjh6dg  H8e2u6ULtJn  g1bv2xjtV0w   \n",
       "35932  202412  zvdAaDU7yC6  EdEpJ41rhF6  SwwuteU1Ajk   \n",
       "35933  202412  zvjggVwOhQP  ydyJb1RAy4U  J7PQPWAeRUk   \n",
       "35934  202412  zzJ3hvbee0l  RXl1ctHnd1A  B1u1bVtIA92   \n",
       "\n",
       "                        facility_name        district_name  \\\n",
       "35930   we Lewanika Referral Hospital    we Mongu District   \n",
       "35931            we Mutwa Health Post  we Senanga District   \n",
       "35932  no Masamba Rural Health Centre    no Mbala District   \n",
       "35933       ea Chimphamba Health Post    ea Chama District   \n",
       "35934            lu Shoti Health Post    lu Mansa District   \n",
       "\n",
       "              province_name        date  AEFI confirmed  AEFI death  ...  \\\n",
       "35930   we Western Province  2024-01-08               0           0  ...   \n",
       "35931   we Western Province  2024-01-08               0           0  ...   \n",
       "35932  no Northern Province  2024-01-08               0           0  ...   \n",
       "35933   ea Eastern Province  2024-01-08               0           0  ...   \n",
       "35934   lu Luapula Province  2024-01-08               0           0  ...   \n",
       "\n",
       "       Typhoid fever confirmed   Typhoid fever death   \\\n",
       "35930                         0                     0   \n",
       "35931                         0                     0   \n",
       "35932                         0                     0   \n",
       "35933                         0                     0   \n",
       "35934                         0                     0   \n",
       "\n",
       "       Typhoid fever sent to Lab   Typhoid fever suspected  \\\n",
       "35930                           0                        0   \n",
       "35931                           0                        0   \n",
       "35932                           0                        0   \n",
       "35933                           0                        0   \n",
       "35934                           0                        0   \n",
       "\n",
       "       VHF (Ebola, Marburg, Lassa Fever, RVF, Crimean-Congo) death   \\\n",
       "35930                                                  0              \n",
       "35931                                                  0              \n",
       "35932                                                  0              \n",
       "35933                                                  0              \n",
       "35934                                                  0              \n",
       "\n",
       "       VHF (Ebola, Marburg, Lassa Fever, RVF, Crimean-Congo) sent to lab  \\\n",
       "35930                                                  0                   \n",
       "35931                                                  0                   \n",
       "35932                                                  0                   \n",
       "35933                                                  0                   \n",
       "35934                                                  0                   \n",
       "\n",
       "       VHF (Ebola, Marburg, Lassa Fever, RVF, Crimean-Congo) suspected  \\\n",
       "35930                                                  0                 \n",
       "35931                                                  0                 \n",
       "35932                                                  0                 \n",
       "35933                                                  0                 \n",
       "35934                                                  0                 \n",
       "\n",
       "       Yellow fever death   Yellow fever sent to lab   Yellow fever suspected  \n",
       "35930                    0                          0                       0  \n",
       "35931                    0                          0                       0  \n",
       "35932                    0                          0                       0  \n",
       "35933                    0                          0                       0  \n",
       "35934                    0                          0                       0  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facility_12_months.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Weekly Data From 2020 to Current Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# DHIS2 instance and API endpoints\n",
    "DHIS2_BASE_URL = \"https:\"\n",
    "API_ENDPOINT_ANALYTICS = \"/api/40/analytics.json\"\n",
    "API_ENDPOINT_DATA_ELEMENTS = \"/api/40/dataElements.json\"\n",
    "\n",
    "# Token authentication\n",
    "TOKEN = \"\"\n",
    "HEADERS = {\"Authorization\": f\"ApiToken {TOKEN}\"}\n",
    "\n",
    "# Step 1: Generate Weekly Period List (from 2020W1 to current week)\n",
    "def generate_weekly_periods(start_year=2020, batch_size=8):\n",
    "    \"\"\"Generate weekly periods grouped into chunks (starting with 8 weeks per request).\"\"\"\n",
    "    today = datetime.today()\n",
    "    current_year, current_week = int(today.strftime(\"%Y\")), int(today.strftime(\"%V\"))\n",
    "\n",
    "    weekly_periods = []\n",
    "    period_batches = []\n",
    "    \n",
    "    for year in range(start_year, current_year + 1):\n",
    "        max_weeks = 53 if datetime(year, 12, 28).isocalendar()[1] == 53 else 52\n",
    "        for week in range(1, max_weeks + 1):\n",
    "            if year == current_year and week > current_week:\n",
    "                break\n",
    "            weekly_periods.append(f\"{year}W{week}\")\n",
    "    \n",
    "    # Group weeks into period chunks (default: 8 weeks per batch)\n",
    "    for i in range(0, len(weekly_periods), batch_size):\n",
    "        period_batches.append(weekly_periods[i:i + batch_size])\n",
    "    \n",
    "    return period_batches\n",
    "\n",
    "weekly_period_batches = generate_weekly_periods()\n",
    "print(f\"Generated {len(weekly_period_batches)} period batches.\")  # Debugging\n",
    "\n",
    "# Step 2: Fetch all data elements dynamically and filter only numeric elements\n",
    "def fetch_aggregatable_data_elements():\n",
    "    response = requests.get(\n",
    "        f\"{DHIS2_BASE_URL}{API_ENDPOINT_DATA_ELEMENTS}?fields=id,valueType,aggregationType&paging=false\",\n",
    "        headers=HEADERS\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Filter only numeric data elements that allow aggregation\n",
    "        valid_data_elements = [\n",
    "            item[\"id\"]\n",
    "            for item in data.get(\"dataElements\", [])\n",
    "            if item.get(\"valueType\") in [\"INTEGER\", \"NUMBER\", \"PERCENTAGE\", \"UNIT_INTERVAL\"]\n",
    "            and item.get(\"aggregationType\") in [\"SUM\", \"AVERAGE\", \"COUNT\"]\n",
    "        ]\n",
    "        \n",
    "        return valid_data_elements\n",
    "    else:\n",
    "        print(f\"Error fetching data elements: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "# Get all valid data element UIDs\n",
    "data_element_uids = fetch_aggregatable_data_elements()\n",
    "\n",
    "if not data_element_uids:\n",
    "    print(\"No valid data elements found. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# Step 3: Split API Requests to Avoid DHIS2 Limits\n",
    "BATCH_SIZE = 200  # Increase data elements per request (from 50 to 200)\n",
    "num_batches = math.ceil(len(data_element_uids) / BATCH_SIZE)\n",
    "\n",
    "# Output CSV file\n",
    "csv_filename = \"dhis2_20_25_facility_data.csv\"\n",
    "all_rows = []\n",
    "\n",
    "# Step 4: Process Data in Batches with Dynamic Period Splitting\n",
    "for batch in range(num_batches):\n",
    "    batch_uids = data_element_uids[batch * BATCH_SIZE : (batch + 1) * BATCH_SIZE]\n",
    "    dx_param = f\"dx:{';'.join(batch_uids)}\"\n",
    "\n",
    "    for period_chunk in weekly_period_batches:\n",
    "        period_param = f\"pe:{';'.join(period_chunk)}\"\n",
    "        max_period_size = len(period_chunk)\n",
    "\n",
    "        while max_period_size > 0:  # Adaptive period splitting loop\n",
    "            print(f\"Processing Batch {batch + 1}/{num_batches}, Period Batch: {period_chunk[:10]}...\")\n",
    "\n",
    "            params = {\n",
    "                \"dimension\": [\n",
    "                    dx_param,\n",
    "                    \"ou:LEVEL-4\",  # Facility-level\n",
    "                    period_param  # Weekly periods chunk\n",
    "                ],\n",
    "                \"displayProperty\": \"NAME\",\n",
    "                \"outputIdScheme\": \"UID\",\n",
    "                \"includeMetadata\": \"true\",\n",
    "                \"includeNames\": \"true\",\n",
    "                \"limit\": 10000,  # Limit results per request\n",
    "                \"paging\": \"true\",\n",
    "                \"page\": 1\n",
    "            }\n",
    "\n",
    "            response = requests.get(\n",
    "                f\"{DHIS2_BASE_URL}{API_ENDPOINT_ANALYTICS}\",\n",
    "                params=params,\n",
    "                headers=HEADERS,\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "\n",
    "                # Extract metadata (UID <-> Name mapping)\n",
    "                metadata = data.get(\"metaData\", {})\n",
    "                data_elements = metadata.get(\"items\", {})\n",
    "\n",
    "                # Extract actual data values\n",
    "                rows = data.get(\"rows\", [])\n",
    "\n",
    "                if not rows:\n",
    "                    break  # No more pages, exit loop\n",
    "\n",
    "                for row in rows:\n",
    "                    data_element_id = row[0]  # Data Element UID\n",
    "                    org_id = row[1]  # Org Unit UID\n",
    "                    period = row[2]  # Period (week)\n",
    "                    value = row[3]  # Reported value\n",
    "\n",
    "                    # Get corresponding names from metadata\n",
    "                    data_element_name = data_elements.get(data_element_id, {}).get(\"name\", data_element_id)\n",
    "\n",
    "                    # Append row to list for processing\n",
    "                    all_rows.append([period, org_id, data_element_name, value])\n",
    "\n",
    "                break  # Successfully retrieved data, move to next period batch\n",
    "\n",
    "            elif response.status_code == 409 and \"Query result set exceeded max limit\" in response.text:\n",
    "                max_period_size //= 2  # Reduce period batch size\n",
    "                period_chunk = period_chunk[:max_period_size]  # Take smaller chunk\n",
    "                period_param = f\"pe:{';'.join(period_chunk)}\"\n",
    "                print(f\"⚠️ Query limit exceeded. Retrying with smaller batch: {max_period_size} weeks.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Error in batch {batch + 1}, period batch {period_chunk[:10]}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "print(f\"Data successfully retrieved. Now processing transformation...\")\n",
    "\n",
    "# Convert list to DataFrame\n",
    "df = pd.DataFrame(all_rows, columns=[\"period\", \"org_id\", \"data_element\", \"value\"])\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert `period` (e.g., \"2025W05\") into proper `date` format (start of the week)\n",
    "def convert_iso_week_to_date(iso_week):\n",
    "    year, week = iso_week[:4], iso_week[5:]\n",
    "    return datetime.strptime(year + week + '1', \"%G%V%w\")  # Monday as start of the week\n",
    "\n",
    "df[\"date\"] = df[\"period\"].apply(lambda x: convert_iso_week_to_date(x).strftime(\"%Y-%m-%dT00:00:00\"))\n",
    "\n",
    "# Pivot the data: Convert `data_element` values into columns\n",
    "df_pivoted = df.pivot_table(\n",
    "    index=[\"period\", \"org_id\", \"date\"],  # Keep these as row identifiers\n",
    "    columns=\"data_element\",  # Each data element becomes a column\n",
    "    values=\"value\",  # Fill with reported values\n",
    "    aggfunc=\"sum\"  # If duplicates exist, aggregate them\n",
    ").reset_index()\n",
    "\n",
    "# Sort Data by `period` (newest to oldest)\n",
    "df_pivoted.sort_values(by=\"period\", ascending=False, inplace=True)\n",
    "\n",
    "# Save Pivoted Data to New CSV\n",
    "pivoted_csv_filename = \"dhis2_20_25_facility_pivoted.csv\"\n",
    "df_pivoted.to_csv(pivoted_csv_filename, index=False)\n",
    "\n",
    "print(f\"Data successfully pivoted, sorted, and saved to {pivoted_csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "credentials_2_path = base_dir / '00_Local' / '01_Configs' / 'credentials2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prod Credentials\n",
    "credentials_2 = {}\n",
    "with credentials_2_path.open('r') as file:\n",
    "    for line in file:\n",
    "        if '=' in line:\n",
    "            key, value = line.strip().split('=', 1)\n",
    "            credentials_2[key.strip()] = value.strip()\n",
    "\n",
    "# Extract values\n",
    "DHIS2_URL = credentials_2.get('DHIS2_URL')\n",
    "USERNAME = credentials_2.get('USERNAME')\n",
    "PASSWORD = credentials_2.get('PASSWORD')\n",
    "PAT = credentials_2.get('PAT')\n",
    "\n",
    "print(\"DHIS2 instance URL:\", DHIS2_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DHIS2 instance and API endpoints\n",
    "API_ENDPOINT_ANALYTICS = \"/api/40/analytics.json\"\n",
    "API_ENDPOINT_DATA_ELEMENTS = \"/api/40/dataElements.json\"\n",
    "\n",
    "# Token authentication\n",
    "# TOKEN = \"\"\n",
    "HEADERS = {\"Authorization\": f\"ApiToken {PAT}\"}\n",
    "\n",
    "# Step 1: Generate Weekly Period List (from 2020W1 to current week)\n",
    "def generate_weekly_periods(start_year=2020, batch_size=8):\n",
    "    \"\"\"Generate weekly periods grouped into chunks (starting with 8 weeks per request).\"\"\"\n",
    "    today = datetime.today()\n",
    "    current_year, current_week = int(today.strftime(\"%Y\")), int(today.strftime(\"%V\"))\n",
    "\n",
    "    weekly_periods = []\n",
    "    period_batches = []\n",
    "    \n",
    "    for year in range(start_year, current_year + 1):\n",
    "        max_weeks = 53 if datetime(year, 12, 28).isocalendar()[1] == 53 else 52\n",
    "        for week in range(1, max_weeks + 1):\n",
    "            if year == current_year and week > current_week:\n",
    "                break\n",
    "            weekly_periods.append(f\"{year}W{week}\")\n",
    "    \n",
    "    # Group weeks into period chunks (default: 8 weeks per batch)\n",
    "    for i in range(0, len(weekly_periods), batch_size):\n",
    "        period_batches.append(weekly_periods[i:i + batch_size])\n",
    "    \n",
    "    return period_batches\n",
    "\n",
    "weekly_period_batches = generate_weekly_periods()\n",
    "print(f\"Generated {len(weekly_period_batches)} period batches.\")  # Debugging\n",
    "\n",
    "# Step 2: Fetch all data elements dynamically and filter only numeric elements\n",
    "def fetch_aggregatable_data_elements():\n",
    "    response = requests.get(\n",
    "        f\"{DHIS2_URL}{API_ENDPOINT_DATA_ELEMENTS}?fields=id,valueType,aggregationType&paging=false\",\n",
    "        headers=HEADERS\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Filter only numeric data elements that allow aggregation\n",
    "        valid_data_elements = [\n",
    "            item[\"id\"]\n",
    "            for item in data.get(\"dataElements\", [])\n",
    "            if item.get(\"valueType\") in [\"INTEGER\", \"NUMBER\", \"PERCENTAGE\", \"UNIT_INTERVAL\"]\n",
    "            and item.get(\"aggregationType\") in [\"SUM\", \"AVERAGE\", \"COUNT\"]\n",
    "        ]\n",
    "        \n",
    "        return valid_data_elements\n",
    "    else:\n",
    "        print(f\"Error fetching data elements: {response.status_code} - {response.text}\")\n",
    "        return []\n",
    "\n",
    "# Get all valid data element UIDs\n",
    "data_element_uids = fetch_aggregatable_data_elements()\n",
    "\n",
    "if not data_element_uids:\n",
    "    print(\"No valid data elements found. Exiting...\")\n",
    "    exit()\n",
    "\n",
    "# Step 3: Split API Requests to Avoid DHIS2 Limits\n",
    "BATCH_SIZE = 200  # Increase data elements per request (from 50 to 200)\n",
    "num_batches = math.ceil(len(data_element_uids) / BATCH_SIZE)\n",
    "\n",
    "# Output CSV file\n",
    "csv_filename = \"ND2_Data_2020W1_to_2025W5.csv\"\n",
    "all_rows = []\n",
    "\n",
    "# Step 4: Process Data in Batches with Dynamic Period Splitting\n",
    "for batch in range(num_batches):\n",
    "    batch_uids = data_element_uids[batch * BATCH_SIZE : (batch + 1) * BATCH_SIZE]\n",
    "    dx_param = f\"dx:{';'.join(batch_uids)}\"\n",
    "\n",
    "    for period_chunk in weekly_period_batches:\n",
    "        period_param = f\"pe:{';'.join(period_chunk)}\"\n",
    "        max_period_size = len(period_chunk)\n",
    "\n",
    "        while max_period_size > 0:  # Adaptive period splitting loop\n",
    "            print(f\"Processing Batch {batch + 1}/{num_batches}, Period Batch: {period_chunk[:10]}...\")\n",
    "\n",
    "            params = {\n",
    "                \"dimension\": [\n",
    "                    dx_param,\n",
    "                    \"ou:LEVEL-4\",  # Facility-level\n",
    "                    period_param  # Weekly periods chunk\n",
    "                ],\n",
    "                \"displayProperty\": \"NAME\",\n",
    "                \"outputIdScheme\": \"UID\",\n",
    "                \"includeMetadata\": \"true\",\n",
    "                \"includeNames\": \"true\",\n",
    "                \"limit\": 10000,  # Limit results per request\n",
    "                \"paging\": \"true\",\n",
    "                \"page\": 1\n",
    "            }\n",
    "\n",
    "            response = requests.get(\n",
    "                f\"{DHIS2_URL}{API_ENDPOINT_ANALYTICS}\",\n",
    "                params=params,\n",
    "                headers=HEADERS,\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "\n",
    "                # Extract metadata (UID <-> Name mapping)\n",
    "                metadata = data.get(\"metaData\", {})\n",
    "                data_elements = metadata.get(\"items\", {})\n",
    "\n",
    "                # Extract actual data values\n",
    "                rows = data.get(\"rows\", [])\n",
    "\n",
    "                if not rows:\n",
    "                    break  # No more pages, exit loop\n",
    "\n",
    "                for row in rows:\n",
    "                    data_element_id = row[0]  # Data Element UID\n",
    "                    org_id = row[1]  # Org Unit UID\n",
    "                    period = row[2]  # Period (week)\n",
    "                    value = row[3]  # Reported value\n",
    "\n",
    "                    # Get corresponding names from metadata\n",
    "                    data_element_name = data_elements.get(data_element_id, {}).get(\"name\", data_element_id)\n",
    "\n",
    "                    # Append row to list for processing\n",
    "                    all_rows.append([period, org_id, data_element_name, value])\n",
    "\n",
    "                break  # Successfully retrieved data, move to next period batch\n",
    "\n",
    "            elif response.status_code == 409 and \"Query result set exceeded max limit\" in response.text:\n",
    "                max_period_size //= 2  # Reduce period batch size\n",
    "                period_chunk = period_chunk[:max_period_size]  # Take smaller chunk\n",
    "                period_param = f\"pe:{';'.join(period_chunk)}\"\n",
    "                print(f\"Query limit exceeded. Retrying with smaller batch: {max_period_size} weeks.\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Error in batch {batch + 1}, period batch {period_chunk[:10]}: {response.status_code} - {response.text}\")\n",
    "                break\n",
    "\n",
    "print(f\"Data successfully retrieved. Now processing transformation...\")\n",
    "\n",
    "# Convert list to DataFrame\n",
    "df = pd.DataFrame(all_rows, columns=[\"period\", \"org_id\", \"data_element\", \"value\"])\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert `period` (e.g., \"2025W05\") into proper `date` format (start of the week)\n",
    "def convert_iso_week_to_date(iso_week):\n",
    "    year, week = iso_week[:4], iso_week[5:]\n",
    "    return datetime.strptime(year + week + '1', \"%G%V%w\")  # Monday as start of the week\n",
    "\n",
    "df[\"date\"] = df[\"period\"].apply(lambda x: convert_iso_week_to_date(x).strftime(\"%Y-%m-%dT00:00:00\"))\n",
    "\n",
    "# Pivot the data: Convert `data_element` values into columns\n",
    "df_pivoted = df.pivot_table(\n",
    "    index=[\"period\", \"org_id\", \"date\"],  # Keep these as row identifiers\n",
    "    columns=\"data_element\",  # Each data element becomes a column\n",
    "    values=\"value\",  # Fill with reported values\n",
    "    aggfunc=\"sum\"  # If duplicates exist, aggregate them\n",
    ").reset_index()\n",
    "\n",
    "# Sort Data by `period` (newest to oldest)\n",
    "df_pivoted.sort_values(by=\"period\", ascending=False, inplace=True)\n",
    "\n",
    "# Save Pivoted Data to New CSV\n",
    "pivoted_csv_filename = \"ND2_Data_2020W1_to_2025W5_Pivoted.csv\"\n",
    "df_pivoted.to_csv(pivoted_csv_filename, index=False)\n",
    "\n",
    "print(f\"Data successfully pivoted, sorted, and saved to {pivoted_csv_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhis2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
